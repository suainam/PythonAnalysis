{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 笔记\n",
    "### 搭建神经网络\n",
    "#### 基本概念\n",
    "+ 基于TensorFlow的NN：用张量表示数据，用计算图搭建神经网络，用会话执行计算图，优化线上权重（参数），得到模型\n",
    "+ 张量：张量就是多为数组（列表），用阶表示张量的维度\n",
    "+ 数据类型：TensorFlow的整数类型有tf.float32、tf.int32等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programes\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1.0,2.0])\n",
    "b = tf.constant([3.0,4.0])\n",
    "result = a+b\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 计算图（Graph）：搭建神经网络的计算过程，是承载1个或多个计算节点的1张图，只搭建网络，不运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul_1:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1.0,2.0]])\n",
    "w = tf.constant([[3.0],[4.0]])\n",
    "y = tf.matmul(x,w)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 会话（Session）：执行计算图中的节点运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络的参数\n",
    "+ 神经网络的参数：神经元线上的权重w，用变量表示，一般会先随机生成这些参数。生成参数的方法是让w等于tf.Variable，把生成的方式写在括号里。\n",
    "+ 神经网络中常用的生成随机数/数组的函数有：\n",
    "    + tf.random_normal() 生成正态分布随机数\n",
    "    + tf.truncated_normal() 生成去掉过大偏离点的正态分布随机数\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([2,3],stddev=2,mean=0,seed=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.truncated_normal([2,3],stddev=2,mean=0,seed=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.random_uniform(shape=[7,],minval=0,maxval=1,dtype=tf.int32,seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'random_uniform_3:0' shape=(7,) dtype=int32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络的搭建\n",
    "当我们知道张量、计算图、会话和参数后，我们讨论神经网络的实现过程\n",
    "+ 神经网络的实现过程：\n",
    "    + 准备数据集，提取特征，作为输入喂给神经网络（Neural Network，NN）\n",
    "    + 搭建NN网络，从输入到输出（先搭建计算图，再用会话执行）\n",
    "        + （NN前向传播算法 --> 计算输出）\n",
    "    + 大量特征数据喂给NN，迭代优化NN参数\n",
    "        + （NN反向传播算法 --> 优化参数训练模型）\n",
    "    + 使用训练好的模型预测和分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 前向传播\n",
    "\n",
    "> 前向传播：搭建模型的计算过程，让模型具有推理能力，可以针对一组输入给出相应的输出\n",
    "\n",
    "+ 第一层\n",
    "    + X是输入为1x2的矩阵\n",
    "    + W（前节点编号，后节点编号）（层数）为待优化参数\n",
    "    + 神经网络共有几层（或当前是第几层网络）都是指的计算层，输入不是计算层\n",
    "        + a为第一层网络，a是一行三列的矩阵\n",
    "+ 第二层\n",
    "    + 参数要满足前面3个节点，后面1个节点，所以W（2）是三行一列矩阵\n",
    "    + 前向传播过程中的tensorflow描述：\n",
    "        + 变量初始化、计算图节点运算都要用会话（with结构）实现\n",
    "```python\n",
    "with tf.Session() as sess:\n",
    "    sess.run()\n",
    "```\n",
    "        + 变量初始化：在sess.run函数中用tf.global_variables_initializer()汇总所有待优化变量\n",
    "```python\n",
    "init_op = tf.global_variables_initializer()\n",
    "seee.run(init_op)\n",
    "```        \n",
    "        + 变量初始化：在sess.run函数中用tf.global_variables_initializer()汇总所有待优化变量  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
